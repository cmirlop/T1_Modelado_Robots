% ----------------------------------------------------------------------------------
% ----------------------------------------------------------------------------------
% ----------------------------------------------------------------------------------
% ----------------------------------------------------------------------------------
\chapter{Materiales y métodos}\label{cap:Sol}

\begin{Resumen}

La sección Materials and Methods (también llamada Methodology o Experimental Section, según la disciplina) es una parte esencial de artículos y memorias de ámbito académico/docente. Su objetivo principal es que otro estudiante, profesor, investigador, ingeniero, etc., pueda reproducir el trabajo siguiendo las descripciones dadas.

\end{Resumen}

\section{Modelado Dinámico}

El objetivo de esta sección es obtener las ecuaciones que gobiernan el movimiento del robot JetBot 3 relacionando los pares aplicados por los motores con las aceleraciones del sistema. Para ello, se utiliza el formalismo de \textbf{Euler-Lagrange}.

\subsection{Hipótesis Adoptadas}
Para la derivación del modelo matemático, se asumen las siguientes simplificaciones sobre la física del robot, basadas en el modelo estándar de robot diferencial descrito en \cite{siegwart2011intro}:
\begin{itemize}
    \item \textbf{Cuerpo Rígido:} El chasis y las ruedas son indeformables.
    \item \textbf{Movimiento Plano:} El robot se desplaza sobre una superficie horizontal, por lo que la energía potencial gravitatoria es constante ($V=0$).
    \item \textbf{Rodadura Pura:} Se asume la condición de no deslizamiento longitudinal ni lateral en las ruedas (restricción no holonómica).
    \item \textbf{Simetría:} Se asume que el centro de masa (CoM) del robot se encuentra en el punto medio del eje que une las dos ruedas motrices.
\end{itemize}

\subsection{Definición de Coordenadas}
La postura del robot en el entorno global se define mediante el vector de coordenadas generalizadas $q$:

\begin{equation}
    q = \begin{bmatrix} x \\ y \\ \theta \end{bmatrix}
\end{equation}

Donde $(x, y)$ representan la posición cartesiana del punto medio del eje de las ruedas y $\theta$ la orientación del chasis respecto al eje $X$ global.

\begin{figure}[h]
    \centering
    % Aquí insertas tu diagrama generado con TikZ o la imagen
    \caption{Esquema cinemático del robot diferencial (JetBot) con las variables de estado y parámetros geométricos.}
    \label{fig:robot_scheme}
\end{figure}

\subsection{Formulación de Euler-Lagrange}
La función Lagrangiana $\mathcal{L}$ se define como la diferencia entre la energía cinética ($T$) y la energía potencial ($V$) del sistema:

\begin{equation}
    \mathcal{L}(q, \dot{q}) = T(q, \dot{q}) - V(q)
\end{equation}

Dado que el movimiento es plano ($V=0$), el Lagrangiano es igual a la energía cinética total, compuesta por la traslación lineal y la rotación angular:

\begin{equation}
    \mathcal{L} = \frac{1}{2} m (\dot{x}^2 + \dot{y}^2) + \frac{1}{2} I_z \dot{\theta}^2
\end{equation}

Siendo $m$ la masa total del robot e $I_z$ el momento de inercia respecto al eje vertical que pasa por el centro de masas.

Las ecuaciones de movimiento se obtienen aplicando la ecuación de Euler-Lagrange:

\begin{equation}
    \frac{d}{dt} \left( \frac{\partial \mathcal{L}}{\partial \dot{q}} \right) - \frac{\partial \mathcal{L}}{\partial q} = B(q)\tau - A^T(q)\lambda
\end{equation}

Donde $\tau$ son las fuerzas generalizadas (pares de los motores), $B(q)$ es la matriz de transformación de entrada y $A^T(q)\lambda$ representa las fuerzas de restricción (fricción de rodadura lateral) que limitan el movimiento a la dirección de las ruedas.

\subsection{Modelo Dinámico Resultante}
Resolviendo las derivadas y considerando la relación cinemática entre la velocidad del robot y la velocidad angular de las ruedas ($\dot{\phi}_R, \dot{\phi}_L$), se llega a la forma compacta del modelo dinámico en el espacio de estados:

\begin{equation}
    \begin{bmatrix} 
    m & 0 & 0 \\ 
    0 & m & 0 \\ 
    0 & 0 & I_z 
    \end{bmatrix}
    \begin{bmatrix} \ddot{x} \\ \ddot{y} \\ \ddot{\theta} \end{bmatrix}
    + \mathbf{F}_{fric}(\dot{q}) 
    = \frac{1}{R}
    \begin{bmatrix} 
    \cos\theta & \cos\theta \\ 
    \sin\theta & \sin\theta \\ 
    L/2 & -L/2 
    \end{bmatrix}
    \begin{bmatrix} \tau_R \\ \tau_L \end{bmatrix}
    \label{eq:final_dynamic}
\end{equation}

Donde:
\begin{itemize}
    \item $R$: Radio de las ruedas.
    \item $L$: Distancia entre las ruedas (ancho de vía).
    \item $\tau_R, \tau_L$: Pares aplicados por los motores derecho e izquierdo.
\end{itemize}

Esta ecuación (\ref{eq:final_dynamic}) describe cómo los pares de los motores aceleran al robot, sujeto a su masa e inercia \cite{siegwart2011intro}.
%Esta ecuación (\ref{eq:final_dynamic}) describe cómo los pares de los motores aceleran al robot, sujeto a su masa e inercia \cite{siegwart2011intro}.

\section{Metodología de control y aprendizaje por refuerzo (RL)}
Explicación de los esquemas de control diseñados: control clásico de referencia, control basado en RL, comparación, etc.
\subsection{Esquema de control}
\subsubsection{Control por LIDAR y cámara}
Este control se basa en el guiado por el entorno basandose en al información recibida por el LIDAR, 
basandose en los datos frontales y laterales que recibimos. Con la cámara lo que hacemos es buscar el color que
tiene el objetivo, en nuestro caso es el color rojo, por lo que se va analizando la imagen constantemente, ya que si detectamos
un área mínima del color del objetivo, extraemos cuanto estamos descentrados para poder centrarse y poder ir recto al 
objetivo.

\subsubsection{Control por RL}


Justificación de la elección de algoritmos de RL (ej.: PPO, SAC, DDPG), con breve descripción de su funcionamiento.
\subsection{Algoritmo RL PPO}



Definición de recompensas, estados y acciones empleados en el entorno de simulación.

\subsection{Recompensas, estados y acciones}
\subsubsection{recompensas}
Las recompensas que se le han asignado al robot se basán en si se ha descubierto area o no dentro de la imagen de 
la cámara. Se han definido zonas de distancia de LIDAR al robot para darle más recompensa o menos:
\begin{itemize}
    \item Distancia frontal libre(FRONT\_CLEAR) : cuando el lidar por delante detecta más de 10m
    \item Distancia frontal peligrosa(FRONT\_DANGER) : Cuando la distancia frontal del LIDAR por delante baja de los 7m
    \item Distancia muy peligrosa : Es la distancia antes del choque donde antes de chocarse prefiero que vaya hacia atrás el robot, 5.5m
\end{itemize}
Primero se comprueban las recompensas por alcanzar el objetivo, o por colisión:
\begin{itemize}
    \item Si se alcanza el objetivo : $+30.0$
    \item Si se ha colisionado : $-8.0$
\end{itemize}
Si no se ha alcanzado el área mínima de 1000px, las recompensas son las siguientes:
\begin{itemize}
    \item Si delante es muy libre, es decir, por encima del umbral FRONT\_CLEAR, y el robot tiene la acción de ir hacia delante rapido o lento le damos $0.3$ por rápido, y $0.15$ por lento
    \item Si delante esta por debajo del umbral FRONT\_DANGER y el robot tiene la accion de ir hacia delante, le quitamos $0.6$
    \item Si delante está por debajo del FRONT\_CLEAR, y giramos hacia el lado que más depejado esta, le damos $0.4$, con esto lo que hacemos es que si por delante vemos una distancia donde no cabe el robot, es inecesario entrar
    dentro de esa sala, es mejor girar
\end{itemize}

\subsubsection{Estados}

\subsubsection{Acciones}
\begin{itemize}
    \item Moverse hacia delante rápido
    \item Moverse hacia delante lento
    \item Moverse fuerte hacia la derecha
    \item Moverse suave hacia la derecha
    \item Moverse fuerte hacia la izquierda
    \item Moverse suave hacia la izquierda
    \item Moverle lento hacia antrás
\end{itemize}


\section{Entorno de simulación y herramientas utilizadas}
Descripción de IsaacSim/IsaacLab: versiones empleadas, configuración inicial y librerías auxiliares. Recursos computacionales (hardware, GPU, sistema operativo).

Configuración de escenarios de entrenamiento (robot, entorno, sensores virtuales, condiciones de interacción).

\subsection{Unity + Visual estudio}
%ros-TCP-connector como libreria

\subsection{Visual estudio code}

\subsection{TensorFlow}
TensorFlow Dashboard es una herramienta que a través de los logs que genera nuestro entrenamiento, va graficando 
cada 4024 pasos, que son 256 por robot, se grafican los resultados.



\subsection{KERAS + gym}



\subsection{ROS 1}
Hemos empleado ROS1 como pasarela de comunicación entre los robots y el máster, que sería nuestro propio ordenador. Lo que hacemos es 
que cada robot tiene unos tópics propios, sobre los cuales envían y reciben la información.




\subsection{Turtle bot}
Aunque en nuestros resultados podemos observar que el robot es un cubo amarillo, lo que se esta haciendo es
simular el comportamiento del turtle bot en un cubo con sus ecuaciones dinámicas


\subsection{Entorno}
Nuestro entorno es un laberito con paredes y pasillos por donde el robot deberá moverse y encontrar el
objetivo de color rojo que puede estar en cualquier lado de la escena.
Se diseñó un mismo entorno, donde en cada instancia el objetivo estaba en una posición diferente como vemos en 
las siguientes imagenes.
\begin{comment}
\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{}
    \caption{Imagen 1}
  \end{subfigure}\hfill
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{}
    \caption{Imagen 2}
  \end{subfigure}
  \caption{Dos imágenes lado a lado}
\end{figure}
\end{comment}





\subsection{Sensores virtuales}
\subsubsection{LIDAR}
Hemos modelado un LIDAR que publica los valores en un topic de ros, es este colisionado
es un codigo de Unity el cual genera una nube de puntos, y los publica todos a través del tópic. En nuestro código lo tratamos
de manera que lo separamos en 180 sectores, esto lo hacemos cogiendo el minimo cada dos sectores.


\subsection{Condiciones de iteraccion}



\section{Procedimiento de experimentación / entrenamiento}
Explicación del flujo de trabajo seguido: preparación de modelos, definición de hiperparámetros, duración de entrenamientos, validación de políticas aprendidas.
\subsection{Flujo de trabajo}
Se probó primero definiendo un escenario muy sencillo, donde si el robot giraba en el primer cruze ya alcanzaba
el objetivo final. Esto se modificó y se hicieron 4 escenarios para el mismo entrenamiento, donde el objetivo estaba 
en diferentes puntos.

Estrategia de comparación: métricas definidas (tiempo de convergencia, estabilidad, error en el seguimiento, etc.).
\subsection{Estrategia de comparacion}
Se definió que cada 1000 pasos en cada robot, se realize una comparcion de modelo, pero se detendria
el entrenamineto si la media de los ultimos 1000 episodios no mejoraba durante los 5 siguientes episodios.


Número de episodios, pruebas o repeticiones realizadas.

\newpage
\section{Programación}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{figuras_Nico/Diagrama_ctrl.png}
    \caption{Diagrama de Flujo del control por LIDAR y cámara}
    \label{fig:my_label}
\end{figure}

%Incluye todas las secciones y subsecciones que tu proyecto necesite para poder entender el trabajo que has realizado